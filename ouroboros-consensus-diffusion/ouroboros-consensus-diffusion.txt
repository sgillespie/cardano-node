-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Integration for the Ouroboros Network layer
--   
--   Top level integration for consensus &amp; network layers of the
--   Ouroboros blockchain protocol.
@package ouroboros-consensus-diffusion
@version 0.10.0.0

module Ouroboros.Consensus.Node.DbLock
newtype DbLocked
DbLocked :: FilePath -> DbLocked

-- | We use an empty file (<a>dbLockFsPath</a>) as a lock of the database
--   so that the database cannot be opened by more than one process. We
--   wait up to <a>dbLockTimeout</a> to take the lock, before timing out
--   and throwing a <a>DbLocked</a> exception.
withLockDB :: MountPoint -> IO a -> IO a

-- | The default lock file
dbLockFsPath :: FsPath

-- | Default time to wait on the lock
dbLockTimeout :: DiffTime

-- | We use the given <a>FsPath</a> in the <a>MountPoint</a> as a lock of
--   the database so that the database cannot be opened by more than one
--   process. We wait the given <a>DiffTime</a> on the thread taking the
--   lock. In case of a timeout, we throw a <a>DbLocked</a> exception.
--   
--   Some systems may delete the empty file when all its handles are
--   closed. This is not an issue, since the file is created if it doesn't
--   exist.
withLockDB_ :: forall m a. (IOLike m, MonadTimer m) => FileLock m -> MountPoint -> FsPath -> DiffTime -> m a -> m a
instance GHC.Show.Show Ouroboros.Consensus.Node.DbLock.DbLocked
instance GHC.Classes.Eq Ouroboros.Consensus.Node.DbLock.DbLocked
instance GHC.Exception.Type.Exception Ouroboros.Consensus.Node.DbLock.DbLocked


-- | Special file we store in the DB dir to avoid unintended deletions
module Ouroboros.Consensus.Node.DbMarker
data DbMarkerError

-- | There was a <a>dbMarkerFile</a> in the database folder, but it
--   contained a different <a>NetworkMagic</a> than the expected one. This
--   indicates that this database folder corresponds to another net.
NetworkMagicMismatch :: FilePath -> NetworkMagic -> NetworkMagic -> DbMarkerError

-- | The database folder contained no <a>dbMarkerFile</a>, but also
--   contained some files. Either the given folder is a non-database folder
--   or it is a database folder, but its <a>dbMarkerFile</a> has been
--   deleted.
NoDbMarkerAndNotEmpty :: FilePath -> DbMarkerError

-- | The database folder contained a <a>dbMarkerFile</a> that could not be
--   read. The file has been tampered with or it was corrupted somehow.
CorruptDbMarker :: FilePath -> DbMarkerError

-- | Check database marker
--   
--   The database folder will contain folders for the ImmutableDB
--   (<tt>immutable</tt>), the VolatileDB (<tt>volatile</tt>), and the
--   LedgerDB (<tt>ledger</tt>). All three subdatabases can delete files
--   from these folders, e.g., outdated files or files that are deemed
--   invalid.
--   
--   For example, when starting a node that will connect to a testnet with
--   a database folder containing mainnet blocks, these blocks will be
--   deemed invalid and will be deleted. This would throw away a perfectly
--   good chain, possibly consisting of gigabytes of data that will have to
--   be synched again.
--   
--   To protect us from unwanted deletion of valid files, we first check
--   whether we have been given the path to the right database folder. We
--   do this by reading the <a>NetworkMagic</a> of the net from a file
--   stored in the root of the database folder. This file's name is defined
--   in <a>dbMarkerFile</a>.
--   
--   <ul>
--   <li>If the <a>NetworkMagic</a> from the file matches that of the net,
--   we have the right database folder.</li>
--   <li>If not, we are opening the wrong database folder and abort by
--   throwing a <a>DbMarkerError</a>.</li>
--   <li>If there is no such file and the folder is empty, we create it and
--   store the net's <a>NetworkMagic</a> in it.</li>
--   <li>If there is no such file, but the folder is not empty, we throw a
--   <a>DbMarkerError</a>, because we have likely been given the wrong
--   path, maybe to a folder containing user or system files. This includes
--   the case that the <a>dbMarkerFile</a> has been deleted.</li>
--   <li>If there is such a <a>dbMarkerFile</a>, but it could not be read
--   or its contents could not be parsed, we also throw a
--   <a>DbMarkerError</a>.</li>
--   </ul>
--   
--   Note that an <a>FsError</a> can also be thrown.
checkDbMarker :: forall m h. MonadThrow m => HasFS m h -> MountPoint -> NetworkMagic -> m (Either DbMarkerError ())
dbMarkerContents :: NetworkMagic -> ByteString

-- | For legacy reasons it was using <tt>ProtocolMagicId</tt> not
--   <a>NetworkMagic</a> which are really the same thing.
dbMarkerFile :: Text

-- | Parse contents of the DB marker file
--   
--   Must be inverse to <a>dbMarkerContents</a>
dbMarkerParse :: Monad m => FilePath -> ByteString -> ExceptT DbMarkerError m NetworkMagic
instance GHC.Show.Show Ouroboros.Consensus.Node.DbMarker.DbMarkerError
instance GHC.Classes.Eq Ouroboros.Consensus.Node.DbMarker.DbMarkerError
instance GHC.Exception.Type.Exception Ouroboros.Consensus.Node.DbMarker.DbMarkerError

module Ouroboros.Consensus.Node.ErrorPolicy
consensusErrorPolicy :: forall blk. (Typeable blk, StandardHash blk) => Proxy blk -> ErrorPolicies

module Ouroboros.Consensus.Node.Exit

-- | The exit code to return when terminating with an exception.
--   
--   To be used in the <tt>ExitFailure</tt> constructor of <a>ExitCode</a>.
--   
--   Note that a node will never turn shut down itself, it is meant to run
--   forever, so it will always terminate with an <a>ExitFailure</a>.
type ExitFailure = Int

-- | Convert an <a>ExitReason</a> to an <a>ExitFailure</a>.
exitReasontoExitFailure :: ExitReason -> ExitFailure

-- | The reason of shutting down
data ExitReason

-- | The node process was killed, by the <tt>kill</tt> command,
--   <tt>CTRL-C</tt> or some other means. This is normal way for a user to
--   terminate the node process. The node can simply be restarted.
Killed :: ExitReason

-- | Something is wrong with the node configuration, the user should check
--   it.
--   
--   For example, for PBFT, it could be that the block signing key and the
--   delegation certificate do not match.
ConfigurationError :: ExitReason

-- | We were unable to open the database, probably the user is using the
--   wrong directory. See <a>DbMarkerError</a> for details.
WrongDatabase :: ExitReason

-- | The disk is full, make some space before restarting the node.
DiskFull :: ExitReason

-- | The database folder doesn't have the right permissions.
InsufficientPermissions :: ExitReason

-- | There is a problem with the network connection, the user should
--   investigate.
--   
--   TODO We're not yet returning this.
NoNetwork :: ExitReason

-- | Something went wrong with the database, restart the node with recovery
--   enabled.
DatabaseCorruption :: ExitReason

-- | Some exception was thrown. The node should just be restarted.
Other :: ExitReason

-- | Return the <a>ExitReason</a> for the given <a>SomeException</a>.
--   Defaults to <a>Other</a>.
toExitReason :: forall blk. (Typeable blk, StandardHash blk) => Proxy blk -> SomeException -> ExitReason

module Ouroboros.Consensus.Node.ExitPolicy

-- | Result of any of the `node-to-node` mini-protocols. We ignore all but
--   `chain-sync` results.
data NodeToNodeInitiatorResult
ChainSyncInitiatorResult :: !ChainSyncClientResult -> NodeToNodeInitiatorResult
NoInitiatorResult :: NodeToNodeInitiatorResult
returnPolicy :: ReturnPolicy NodeToNodeInitiatorResult
type ReturnPolicy a = a -> RepromoteDelay

module Ouroboros.Consensus.Node.Recovery

-- | Did the ChainDB already have existing clean-shutdown marker on disk?
newtype LastShutDownWasClean
LastShutDownWasClean :: Bool -> LastShutDownWasClean

-- | Create the <a>cleanShutdownMarkerFile</a>.
--   
--   Idempotent.
createCleanShutdownMarker :: IOLike m => HasFS m h -> m ()

-- | Return <a>True</a> when <a>cleanShutdownMarkerFile</a> exists.
hasCleanShutdownMarker :: HasFS m h -> m Bool

-- | Remove <a>cleanShutdownMarkerFile</a>.
--   
--   Will throw an <tt>FsResourceDoesNotExist</tt> error when it does not
--   exist.
removeCleanShutdownMarker :: HasFS m h -> m ()

-- | A bracket function that manages the clean-shutdown marker on disk.
--   
--   <ul>
--   <li>If the marker is missing on startup, then ChainDB initialization
--   will revalidate the database contents.</li>
--   <li>If the OS kills the nodes, then we don't have the opportunity to
--   write out the marker file, which is fine, since we want the next
--   startup to do revalidation.</li>
--   <li>If initialization was cleanly interrupted (eg SIGINT), then we
--   leave the marker the marker in the same state as it was at the
--   beginning of said initialization.</li>
--   <li>At the end of a successful initialization, we remove the marker
--   and install a shutdown handler that writes the marker except for
--   certain exceptions (see <a>exceptionRequiresRecovery</a>) that
--   indicate corruption, for which we want the next startup to do
--   revalidation.</li>
--   </ul>
runWithCheckedDB :: forall a m h blk. (IOLike m, StandardHash blk, Typeable blk) => Proxy blk -> HasFS m h -> (LastShutDownWasClean -> (ChainDB m blk -> m a -> m a) -> m a) -> m a
instance GHC.Show.Show Ouroboros.Consensus.Node.Recovery.LastShutDownWasClean
instance GHC.Classes.Eq Ouroboros.Consensus.Node.Recovery.LastShutDownWasClean

module Ouroboros.Consensus.Node.RethrowPolicy
consensusRethrowPolicy :: forall blk. (Typeable blk, StandardHash blk) => Proxy blk -> RethrowPolicy

module Ouroboros.Consensus.Node.Tracers

-- | A record of <a>Tracer</a>s for the node.
type Tracers m remotePeer localPeer blk = Tracers' remotePeer localPeer blk (Tracer m)
data Tracers' remotePeer localPeer blk f
Tracers :: f (TraceLabelPeer remotePeer (TraceChainSyncClientEvent blk)) -> f (TraceLabelPeer remotePeer (TraceChainSyncServerEvent blk)) -> f (TraceChainSyncServerEvent blk) -> f [TraceLabelPeer remotePeer (FetchDecision [Point (Header blk)])] -> f (TraceLabelPeer remotePeer (TraceFetchClientState (Header blk))) -> f (TraceLabelPeer remotePeer (TraceBlockFetchServerEvent blk)) -> f (TraceLabelPeer remotePeer (TraceTxSubmissionInbound (GenTxId blk) (GenTx blk))) -> f (TraceLabelPeer remotePeer (TraceTxSubmissionOutbound (GenTxId blk) (GenTx blk))) -> f (TraceLocalTxSubmissionServerEvent blk) -> f (TraceEventMempool blk) -> f (TraceLabelCreds (TraceForgeEvent blk)) -> f (TraceBlockchainTimeEvent UTCTime) -> f (TraceLabelCreds (ForgeStateInfo blk)) -> f (TraceKeepAliveClient remotePeer) -> f SomeException -> Tracers' remotePeer localPeer blk f
[chainSyncClientTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceChainSyncClientEvent blk))
[chainSyncServerHeaderTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceChainSyncServerEvent blk))
[chainSyncServerBlockTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceChainSyncServerEvent blk)
[blockFetchDecisionTracer] :: Tracers' remotePeer localPeer blk f -> f [TraceLabelPeer remotePeer (FetchDecision [Point (Header blk)])]
[blockFetchClientTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceFetchClientState (Header blk)))
[blockFetchServerTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceBlockFetchServerEvent blk))
[txInboundTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceTxSubmissionInbound (GenTxId blk) (GenTx blk)))
[txOutboundTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceTxSubmissionOutbound (GenTxId blk) (GenTx blk)))
[localTxSubmissionServerTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLocalTxSubmissionServerEvent blk)
[mempoolTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceEventMempool blk)
[forgeTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelCreds (TraceForgeEvent blk))
[blockchainTimeTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceBlockchainTimeEvent UTCTime)
[forgeStateInfoTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelCreds (ForgeStateInfo blk))
[keepAliveClientTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceKeepAliveClient remotePeer)
[consensusErrorTracer] :: Tracers' remotePeer localPeer blk f -> f SomeException

-- | Use a <a>nullTracer</a> for each of the <a>Tracer</a>s in
--   <a>Tracers'</a>
nullTracers :: Monad m => Tracers m remotePeer localPeer blk
showTracers :: (Show blk, Show (GenTx blk), Show (Validated (GenTx blk)), Show (GenTxId blk), Show (ApplyTxErr blk), Show (Header blk), Show (ForgeStateInfo blk), Show (ForgeStateUpdateError blk), Show (CannotForge blk), Show remotePeer, LedgerSupportsProtocol blk) => Tracer m String -> Tracers m remotePeer localPeer blk

-- | Trace the forging of a block as a slot leader.
--   
--   The flow of trace events here can be visualized as follows:
--   
--   <pre>
--   TraceStartLeadershipCheck
--            |
--            +--- TraceSlotIsImmutable (leadership check failed)
--            |
--            +--- TraceBlockFromFuture (leadership check failed)
--            |
--    TraceBlockContext
--            |
--            +--- TraceNoLedgerState (leadership check failed)
--            |
--     TraceLedgerState
--            |
--            +--- TraceNoLedgerView (leadership check failed)
--            |
--     TraceLedgerView
--            |
--            +--- TraceForgeStateUpdateError (leadership check failed)
--            |
--            +--- TraceNodeCannotForge (leadership check failed)
--            |
--            +--- TraceNodeNotLeader
--            |
--     TraceNodeIsLeader
--            |
--      TraceForgedBlock
--            |
--            +--- TraceDidntAdoptBlock
--            |
--            +--- TraceForgedInvalidBlock
--            |
--    TraceAdoptedBlock
--   </pre>
data TraceForgeEvent blk

-- | Start of the leadership check
--   
--   We record the current slot number.
TraceStartLeadershipCheck :: SlotNo -> TraceForgeEvent blk

-- | Leadership check failed: the tip of the ImmutableDB inhabits the
--   current slot
--   
--   This might happen in two cases.
--   
--   <ol>
--   <li>the clock moved backwards, on restart we ignored everything from
--   the VolatileDB since it's all in the future, and now the tip of the
--   ImmutableDB points to a block produced in the same slot we're trying
--   to produce a block in</li>
--   <li>k = 0 and we already adopted a block from another leader of the
--   same slot.</li>
--   </ol>
--   
--   We record both the current slot number as well as the tip of the
--   ImmutableDB.
--   
--   See also
--   <a>https://github.com/IntersectMBO/ouroboros-network/issues/1462</a>
TraceSlotIsImmutable :: SlotNo -> Point blk -> BlockNo -> TraceForgeEvent blk

-- | Leadership check failed: the current chain contains a block from a
--   slot <i>after</i> the current slot
--   
--   This can only happen if the system is under heavy load.
--   
--   We record both the current slot number as well as the slot number of
--   the block at the tip of the chain.
--   
--   See also
--   <a>https://github.com/IntersectMBO/ouroboros-network/issues/1462</a>
TraceBlockFromFuture :: SlotNo -> SlotNo -> TraceForgeEvent blk

-- | We found out to which block we are going to connect the block we are
--   about to forge.
--   
--   We record the current slot number, the block number of the block to
--   connect to and its point.
--   
--   Note that block number of the block we will try to forge is one more
--   than the recorded block number.
TraceBlockContext :: SlotNo -> BlockNo -> Point blk -> TraceForgeEvent blk

-- | Leadership check failed: we were unable to get the ledger state for
--   the point of the block we want to connect to
--   
--   This can happen if after choosing which block to connect to the node
--   switched to a different fork. We expect this to happen only rather
--   rarely, so this certainly merits a warning; if it happens a lot, that
--   merits an investigation.
--   
--   We record both the current slot number as well as the point of the
--   block we attempt to connect the new block to (that we requested the
--   ledger state for).
TraceNoLedgerState :: SlotNo -> Point blk -> TraceForgeEvent blk

-- | We obtained a ledger state for the point of the block we want to
--   connect to
--   
--   We record both the current slot number as well as the point of the
--   block we attempt to connect the new block to (that we requested the
--   ledger state for).
TraceLedgerState :: SlotNo -> Point blk -> TraceForgeEvent blk

-- | Leadership check failed: we were unable to get the ledger view for the
--   current slot number
--   
--   This will only happen if there are many missing blocks between the tip
--   of our chain and the current slot.
--   
--   We record also the failure returned by <tt>forecastFor</tt>.
TraceNoLedgerView :: SlotNo -> OutsideForecastRange -> TraceForgeEvent blk

-- | We obtained a ledger view for the current slot number
--   
--   We record the current slot number.
TraceLedgerView :: SlotNo -> TraceForgeEvent blk

-- | Updating the forge state failed.
--   
--   For example, the KES key could not be evolved anymore.
--   
--   We record the error returned by <a>updateForgeState</a>.
TraceForgeStateUpdateError :: SlotNo -> ForgeStateUpdateError blk -> TraceForgeEvent blk

-- | We did the leadership check and concluded that we should lead and
--   forge a block, but cannot.
--   
--   This should only happen rarely and should be logged with warning
--   severity.
--   
--   Records why we cannot forge a block.
TraceNodeCannotForge :: SlotNo -> CannotForge blk -> TraceForgeEvent blk

-- | We did the leadership check and concluded we are not the leader
--   
--   We record the current slot number
TraceNodeNotLeader :: SlotNo -> TraceForgeEvent blk

-- | We did the leadership check and concluded we <i>are</i> the leader
--   
--   The node will soon forge; it is about to read its transactions from
--   the Mempool. This will be followed by TraceForgedBlock.
TraceNodeIsLeader :: SlotNo -> TraceForgeEvent blk

-- | We ticked the ledger state for the slot of the to-be-forged block.
--   
--   We record the current slot number and the point of the block we
--   attempt to connect the new block to.
TraceForgeTickedLedgerState :: SlotNo -> Point blk -> TraceForgeEvent blk

-- | We acquired a mempool snapshot.
--   
--   We record the the point of the state we are starting from (ie the
--   point from <a>TraceLedgerState</a>) and point the mempool had most
--   last synced wrt.
TraceForgingMempoolSnapshot :: SlotNo -> Point blk -> ChainHash blk -> SlotNo -> TraceForgeEvent blk

-- | We forged a block
--   
--   We record the current slot number, the point of the predecessor, the
--   block itself, and the total size of the mempool snapshot at the time
--   we produced the block (which may be significantly larger than the
--   block, due to maximum block size)
--   
--   This will be followed by one of three messages:
--   
--   <ul>
--   <li>TraceAdoptedBlock (normally)</li>
--   <li>TraceDidntAdoptBlock (rarely)</li>
--   <li>TraceForgedInvalidBlock (hopefully never -- this would indicate a
--   bug)</li>
--   </ul>
TraceForgedBlock :: SlotNo -> Point blk -> blk -> MempoolSize -> TraceForgeEvent blk

-- | We did not adopt the block we produced, but the block was valid. We
--   must have adopted a block that another leader of the same slot
--   produced before we got the chance of adopting our own block. This is
--   very rare, this warrants a warning.
TraceDidntAdoptBlock :: SlotNo -> blk -> TraceForgeEvent blk

-- | We did not adopt the block we produced, because the adoption thread
--   died. Most likely because of an async exception.
TraceAdoptionThreadDied :: SlotNo -> blk -> TraceForgeEvent blk

-- | We forged a block that is invalid according to the ledger in the
--   ChainDB. This means there is an inconsistency between the mempool
--   validation and the ledger validation. This is a serious error!
TraceForgedInvalidBlock :: SlotNo -> blk -> InvalidBlockReason blk -> TraceForgeEvent blk

-- | We adopted the block we produced, we also trace the transactions that
--   were adopted.
TraceAdoptedBlock :: SlotNo -> blk -> [Validated (GenTx blk)] -> TraceForgeEvent blk

-- | Label a forge-related trace event with the label associated with its
--   credentials.
--   
--   This is useful when a node is running with multiple sets of
--   credentials.
data TraceLabelCreds a
TraceLabelCreds :: Text -> a -> TraceLabelCreds a
instance GHC.Base.Functor Ouroboros.Consensus.Node.Tracers.TraceLabelCreds
instance GHC.Show.Show a => GHC.Show.Show (Ouroboros.Consensus.Node.Tracers.TraceLabelCreds a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Ouroboros.Consensus.Node.Tracers.TraceLabelCreds a)
instance (Ouroboros.Consensus.Ledger.SupportsProtocol.LedgerSupportsProtocol blk, GHC.Classes.Eq blk, GHC.Classes.Eq (Ouroboros.Consensus.Ledger.Abstract.Validated (Ouroboros.Consensus.Ledger.SupportsMempool.GenTx blk)), GHC.Classes.Eq (Ouroboros.Consensus.Block.Forging.ForgeStateUpdateError blk), GHC.Classes.Eq (Ouroboros.Consensus.Block.Forging.CannotForge blk)) => GHC.Classes.Eq (Ouroboros.Consensus.Node.Tracers.TraceForgeEvent blk)
instance (Ouroboros.Consensus.Ledger.SupportsProtocol.LedgerSupportsProtocol blk, GHC.Show.Show blk, GHC.Show.Show (Ouroboros.Consensus.Ledger.Abstract.Validated (Ouroboros.Consensus.Ledger.SupportsMempool.GenTx blk)), GHC.Show.Show (Ouroboros.Consensus.Block.Forging.ForgeStateUpdateError blk), GHC.Show.Show (Ouroboros.Consensus.Block.Forging.CannotForge blk)) => GHC.Show.Show (Ouroboros.Consensus.Node.Tracers.TraceForgeEvent blk)
instance (forall a. GHC.Base.Semigroup (f a)) => GHC.Base.Semigroup (Ouroboros.Consensus.Node.Tracers.Tracers' remotePeer localPeer blk f)

module Ouroboros.Consensus.NodeKernel
data () => MempoolCapacityBytesOverride
NoMempoolCapacityBytesOverride :: MempoolCapacityBytesOverride
MempoolCapacityBytesOverride :: !MempoolCapacityBytes -> MempoolCapacityBytesOverride

-- | Interface against running relay node
data NodeKernel m addrNTN addrNTC blk
NodeKernel :: ChainDB m blk -> Mempool m blk -> TopLevelConfig blk -> FetchClientRegistry (ConnectionId addrNTN) (Header blk) blk m -> STM m FetchMode -> StrictTVar m (Map (ConnectionId addrNTN) (StrictTVar m (AnchoredFragment (Header blk)))) -> PeerSharingRegistry addrNTN m -> Tracers m (ConnectionId addrNTN) addrNTC blk -> ([BlockForging m blk] -> m ()) -> NodeKernel m addrNTN addrNTC blk

-- | The <a>ChainDB</a> of the node
[$sel:getChainDB:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> ChainDB m blk

-- | The node's mempool
[$sel:getMempool:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> Mempool m blk

-- | The node's top-level static configuration
[$sel:getTopLevelConfig:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> TopLevelConfig blk

-- | The fetch client registry, used for the block fetch clients.
[$sel:getFetchClientRegistry:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> FetchClientRegistry (ConnectionId addrNTN) (Header blk) blk m

-- | The fetch mode, used by diffusion.
[$sel:getFetchMode:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> STM m FetchMode

-- | Read the current candidates
[$sel:getNodeCandidates:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> StrictTVar m (Map (ConnectionId addrNTN) (StrictTVar m (AnchoredFragment (Header blk))))

-- | Read the current peer sharing registry, used for interacting with the
--   PeerSharing protocol
[$sel:getPeerSharingRegistry:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> PeerSharingRegistry addrNTN m

-- | The node's tracers
[$sel:getTracers:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> Tracers m (ConnectionId addrNTN) addrNTC blk

-- | Set block forging
--   
--   When set with the empty list '[]' block forging will be disabled.
[$sel:setBlockForging:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> [BlockForging m blk] -> m ()

-- | Arguments required when initializing a node
data NodeKernelArgs m addrNTN addrNTC blk
NodeKernelArgs :: Tracers m (ConnectionId addrNTN) addrNTC blk -> ResourceRegistry m -> TopLevelConfig blk -> BlockchainTime m -> ChainDB m blk -> (StorageConfig blk -> InitChainDB m blk -> m ()) -> SomeHeaderInFutureCheck m blk -> (Header blk -> SizeInBytes) -> MempoolCapacityBytesOverride -> MiniProtocolParameters -> BlockFetchConfiguration -> StdGen -> NodeKernelArgs m addrNTN addrNTC blk
[$sel:tracers:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> Tracers m (ConnectionId addrNTN) addrNTC blk
[$sel:registry:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> ResourceRegistry m
[$sel:cfg:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> TopLevelConfig blk
[$sel:btime:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> BlockchainTime m
[$sel:chainDB:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> ChainDB m blk
[$sel:initChainDB:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> StorageConfig blk -> InitChainDB m blk -> m ()
[$sel:chainSyncFutureCheck:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> SomeHeaderInFutureCheck m blk
[$sel:blockFetchSize:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> Header blk -> SizeInBytes
[$sel:mempoolCapacityOverride:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> MempoolCapacityBytesOverride
[$sel:miniProtocolParameters:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> MiniProtocolParameters
[$sel:blockFetchConfiguration:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> BlockFetchConfiguration
[$sel:keepAliveRng:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> StdGen

-- | Trace the forging of a block as a slot leader.
--   
--   The flow of trace events here can be visualized as follows:
--   
--   <pre>
--   TraceStartLeadershipCheck
--            |
--            +--- TraceSlotIsImmutable (leadership check failed)
--            |
--            +--- TraceBlockFromFuture (leadership check failed)
--            |
--    TraceBlockContext
--            |
--            +--- TraceNoLedgerState (leadership check failed)
--            |
--     TraceLedgerState
--            |
--            +--- TraceNoLedgerView (leadership check failed)
--            |
--     TraceLedgerView
--            |
--            +--- TraceForgeStateUpdateError (leadership check failed)
--            |
--            +--- TraceNodeCannotForge (leadership check failed)
--            |
--            +--- TraceNodeNotLeader
--            |
--     TraceNodeIsLeader
--            |
--      TraceForgedBlock
--            |
--            +--- TraceDidntAdoptBlock
--            |
--            +--- TraceForgedInvalidBlock
--            |
--    TraceAdoptedBlock
--   </pre>
data TraceForgeEvent blk

-- | Start of the leadership check
--   
--   We record the current slot number.
TraceStartLeadershipCheck :: SlotNo -> TraceForgeEvent blk

-- | Leadership check failed: the tip of the ImmutableDB inhabits the
--   current slot
--   
--   This might happen in two cases.
--   
--   <ol>
--   <li>the clock moved backwards, on restart we ignored everything from
--   the VolatileDB since it's all in the future, and now the tip of the
--   ImmutableDB points to a block produced in the same slot we're trying
--   to produce a block in</li>
--   <li>k = 0 and we already adopted a block from another leader of the
--   same slot.</li>
--   </ol>
--   
--   We record both the current slot number as well as the tip of the
--   ImmutableDB.
--   
--   See also
--   <a>https://github.com/IntersectMBO/ouroboros-network/issues/1462</a>
TraceSlotIsImmutable :: SlotNo -> Point blk -> BlockNo -> TraceForgeEvent blk

-- | Leadership check failed: the current chain contains a block from a
--   slot <i>after</i> the current slot
--   
--   This can only happen if the system is under heavy load.
--   
--   We record both the current slot number as well as the slot number of
--   the block at the tip of the chain.
--   
--   See also
--   <a>https://github.com/IntersectMBO/ouroboros-network/issues/1462</a>
TraceBlockFromFuture :: SlotNo -> SlotNo -> TraceForgeEvent blk

-- | We found out to which block we are going to connect the block we are
--   about to forge.
--   
--   We record the current slot number, the block number of the block to
--   connect to and its point.
--   
--   Note that block number of the block we will try to forge is one more
--   than the recorded block number.
TraceBlockContext :: SlotNo -> BlockNo -> Point blk -> TraceForgeEvent blk

-- | Leadership check failed: we were unable to get the ledger state for
--   the point of the block we want to connect to
--   
--   This can happen if after choosing which block to connect to the node
--   switched to a different fork. We expect this to happen only rather
--   rarely, so this certainly merits a warning; if it happens a lot, that
--   merits an investigation.
--   
--   We record both the current slot number as well as the point of the
--   block we attempt to connect the new block to (that we requested the
--   ledger state for).
TraceNoLedgerState :: SlotNo -> Point blk -> TraceForgeEvent blk

-- | We obtained a ledger state for the point of the block we want to
--   connect to
--   
--   We record both the current slot number as well as the point of the
--   block we attempt to connect the new block to (that we requested the
--   ledger state for).
TraceLedgerState :: SlotNo -> Point blk -> TraceForgeEvent blk

-- | Leadership check failed: we were unable to get the ledger view for the
--   current slot number
--   
--   This will only happen if there are many missing blocks between the tip
--   of our chain and the current slot.
--   
--   We record also the failure returned by <tt>forecastFor</tt>.
TraceNoLedgerView :: SlotNo -> OutsideForecastRange -> TraceForgeEvent blk

-- | We obtained a ledger view for the current slot number
--   
--   We record the current slot number.
TraceLedgerView :: SlotNo -> TraceForgeEvent blk

-- | Updating the forge state failed.
--   
--   For example, the KES key could not be evolved anymore.
--   
--   We record the error returned by <a>updateForgeState</a>.
TraceForgeStateUpdateError :: SlotNo -> ForgeStateUpdateError blk -> TraceForgeEvent blk

-- | We did the leadership check and concluded that we should lead and
--   forge a block, but cannot.
--   
--   This should only happen rarely and should be logged with warning
--   severity.
--   
--   Records why we cannot forge a block.
TraceNodeCannotForge :: SlotNo -> CannotForge blk -> TraceForgeEvent blk

-- | We did the leadership check and concluded we are not the leader
--   
--   We record the current slot number
TraceNodeNotLeader :: SlotNo -> TraceForgeEvent blk

-- | We did the leadership check and concluded we <i>are</i> the leader
--   
--   The node will soon forge; it is about to read its transactions from
--   the Mempool. This will be followed by TraceForgedBlock.
TraceNodeIsLeader :: SlotNo -> TraceForgeEvent blk

-- | We ticked the ledger state for the slot of the to-be-forged block.
--   
--   We record the current slot number and the point of the block we
--   attempt to connect the new block to.
TraceForgeTickedLedgerState :: SlotNo -> Point blk -> TraceForgeEvent blk

-- | We acquired a mempool snapshot.
--   
--   We record the the point of the state we are starting from (ie the
--   point from <a>TraceLedgerState</a>) and point the mempool had most
--   last synced wrt.
TraceForgingMempoolSnapshot :: SlotNo -> Point blk -> ChainHash blk -> SlotNo -> TraceForgeEvent blk

-- | We forged a block
--   
--   We record the current slot number, the point of the predecessor, the
--   block itself, and the total size of the mempool snapshot at the time
--   we produced the block (which may be significantly larger than the
--   block, due to maximum block size)
--   
--   This will be followed by one of three messages:
--   
--   <ul>
--   <li>TraceAdoptedBlock (normally)</li>
--   <li>TraceDidntAdoptBlock (rarely)</li>
--   <li>TraceForgedInvalidBlock (hopefully never -- this would indicate a
--   bug)</li>
--   </ul>
TraceForgedBlock :: SlotNo -> Point blk -> blk -> MempoolSize -> TraceForgeEvent blk

-- | We did not adopt the block we produced, but the block was valid. We
--   must have adopted a block that another leader of the same slot
--   produced before we got the chance of adopting our own block. This is
--   very rare, this warrants a warning.
TraceDidntAdoptBlock :: SlotNo -> blk -> TraceForgeEvent blk

-- | We did not adopt the block we produced, because the adoption thread
--   died. Most likely because of an async exception.
TraceAdoptionThreadDied :: SlotNo -> blk -> TraceForgeEvent blk

-- | We forged a block that is invalid according to the ledger in the
--   ChainDB. This means there is an inconsistency between the mempool
--   validation and the ledger validation. This is a serious error!
TraceForgedInvalidBlock :: SlotNo -> blk -> InvalidBlockReason blk -> TraceForgeEvent blk

-- | We adopted the block we produced, we also trace the transactions that
--   were adopted.
TraceAdoptedBlock :: SlotNo -> blk -> [Validated (GenTx blk)] -> TraceForgeEvent blk
getMempoolReader :: forall m blk. (LedgerSupportsMempool blk, IOLike m, HasTxId (GenTx blk)) => Mempool m blk -> TxSubmissionMempoolReader (GenTxId blk) (Validated (GenTx blk)) TicketNo m
getMempoolWriter :: (LedgerSupportsMempool blk, IOLike m, HasTxId (GenTx blk)) => Mempool m blk -> TxSubmissionMempoolWriter (GenTxId blk) (GenTx blk) TicketNo m

-- | Retrieve the peers registered in the current chain/ledger state by
--   descending stake.
--   
--   For example, for Shelley, this will return the stake pool relays
--   ordered by descending stake.
--   
--   Only returns a <a>Just</a> when the given predicate returns
--   <a>True</a>. This predicate can for example check whether the slot of
--   the ledger state is older or newer than some slot number.
--   
--   We don't use the ledger state at the tip of the chain, but the ledger
--   state <tt>k</tt> blocks back, i.e., at the tip of the immutable chain,
--   because any stake pools registered in that ledger state are guaranteed
--   to be stable. This justifies merging the future and current stake
--   pools.
getPeersFromCurrentLedger :: (IOLike m, LedgerSupportsPeerSelection blk) => NodeKernel m addrNTN addrNTC blk -> (LedgerState blk -> Bool) -> STM m (Maybe [(PoolStake, NonEmpty RelayAccessPoint)])

-- | Like <a>getPeersFromCurrentLedger</a> but with a "after slot number X"
--   condition.
getPeersFromCurrentLedgerAfterSlot :: forall m blk addrNTN addrNTC. (IOLike m, LedgerSupportsPeerSelection blk, UpdateLedger blk) => NodeKernel m addrNTN addrNTC blk -> SlotNo -> STM m (Maybe [(PoolStake, NonEmpty RelayAccessPoint)])
initNodeKernel :: forall m addrNTN addrNTC blk. (IOLike m, RunNode blk, Ord addrNTN, Hashable addrNTN, Typeable addrNTN) => NodeKernelArgs m addrNTN addrNTC blk -> m (NodeKernel m addrNTN addrNTC blk)


-- | Intended for qualified import
module Ouroboros.Consensus.Network.NodeToNode

-- | Protocol handlers for node-to-node (remote) communication
data Handlers m addr blk
Handlers :: (ConnectionId addr -> IsBigLedgerPeer -> DynamicEnv m blk -> ChainSyncClientPipelined (Header blk) (Point blk) (Tip blk) m ChainSyncClientResult) -> (ConnectionId addr -> NodeToNodeVersion -> Follower m blk (WithPoint blk (SerialisedHeader blk)) -> ChainSyncServer (SerialisedHeader blk) (Point blk) (Tip blk) m ()) -> (NodeToNodeVersion -> ControlMessageSTM m -> FetchedMetricsTracer m -> BlockFetchClient (Header blk) blk m ()) -> (ConnectionId addr -> NodeToNodeVersion -> ResourceRegistry m -> BlockFetchServer (Serialised blk) (Point blk) m ()) -> (NodeToNodeVersion -> ControlMessageSTM m -> ConnectionId addr -> TxSubmissionClient (GenTxId blk) (GenTx blk) m ()) -> (NodeToNodeVersion -> ConnectionId addr -> TxSubmissionServerPipelined (GenTxId blk) (GenTx blk) m ()) -> (NodeToNodeVersion -> ControlMessageSTM m -> ConnectionId addr -> StrictTVar m (Map (ConnectionId addr) PeerGSV) -> KeepAliveInterval -> KeepAliveClient m ()) -> (NodeToNodeVersion -> ConnectionId addr -> KeepAliveServer m ()) -> (NodeToNodeVersion -> ControlMessageSTM m -> ConnectionId addr -> PeerSharingController addr m -> m (PeerSharingClient addr m ())) -> (NodeToNodeVersion -> ConnectionId addr -> PeerSharingServer addr m) -> Handlers m addr blk
[hChainSyncClient] :: Handlers m addr blk -> ConnectionId addr -> IsBigLedgerPeer -> DynamicEnv m blk -> ChainSyncClientPipelined (Header blk) (Point blk) (Tip blk) m ChainSyncClientResult
[hChainSyncServer] :: Handlers m addr blk -> ConnectionId addr -> NodeToNodeVersion -> Follower m blk (WithPoint blk (SerialisedHeader blk)) -> ChainSyncServer (SerialisedHeader blk) (Point blk) (Tip blk) m ()
[hBlockFetchClient] :: Handlers m addr blk -> NodeToNodeVersion -> ControlMessageSTM m -> FetchedMetricsTracer m -> BlockFetchClient (Header blk) blk m ()
[hBlockFetchServer] :: Handlers m addr blk -> ConnectionId addr -> NodeToNodeVersion -> ResourceRegistry m -> BlockFetchServer (Serialised blk) (Point blk) m ()
[hTxSubmissionClient] :: Handlers m addr blk -> NodeToNodeVersion -> ControlMessageSTM m -> ConnectionId addr -> TxSubmissionClient (GenTxId blk) (GenTx blk) m ()
[hTxSubmissionServer] :: Handlers m addr blk -> NodeToNodeVersion -> ConnectionId addr -> TxSubmissionServerPipelined (GenTxId blk) (GenTx blk) m ()
[hKeepAliveClient] :: Handlers m addr blk -> NodeToNodeVersion -> ControlMessageSTM m -> ConnectionId addr -> StrictTVar m (Map (ConnectionId addr) PeerGSV) -> KeepAliveInterval -> KeepAliveClient m ()
[hKeepAliveServer] :: Handlers m addr blk -> NodeToNodeVersion -> ConnectionId addr -> KeepAliveServer m ()
[hPeerSharingClient] :: Handlers m addr blk -> NodeToNodeVersion -> ControlMessageSTM m -> ConnectionId addr -> PeerSharingController addr m -> m (PeerSharingClient addr m ())
[hPeerSharingServer] :: Handlers m addr blk -> NodeToNodeVersion -> ConnectionId addr -> PeerSharingServer addr m
mkHandlers :: forall m blk addrNTN addrNTC. (IOLike m, MonadTime m, MonadTimer m, LedgerSupportsMempool blk, HasTxId (GenTx blk), LedgerSupportsProtocol blk, Ord addrNTN) => NodeKernelArgs m addrNTN addrNTC blk -> NodeKernel m addrNTN addrNTC blk -> (PeerSharingAmount -> m [addrNTN]) -> Handlers m addrNTN blk

-- | Node-to-node protocol codecs needed to run <a>Handlers</a>.
data Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS
Codecs :: Codec (ChainSync (Header blk) (Point blk) (Tip blk)) e m bCS -> Codec (ChainSync (SerialisedHeader blk) (Point blk) (Tip blk)) e m bSCS -> Codec (BlockFetch blk (Point blk)) e m bBF -> Codec (BlockFetch (Serialised blk) (Point blk)) e m bSBF -> Codec (TxSubmission2 (GenTxId blk) (GenTx blk)) e m bTX -> Codec KeepAlive e m bKA -> Codec (PeerSharing addr) e m bPS -> Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS
[cChainSyncCodec] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec (ChainSync (Header blk) (Point blk) (Tip blk)) e m bCS
[cChainSyncCodecSerialised] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec (ChainSync (SerialisedHeader blk) (Point blk) (Tip blk)) e m bSCS
[cBlockFetchCodec] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec (BlockFetch blk (Point blk)) e m bBF
[cBlockFetchCodecSerialised] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec (BlockFetch (Serialised blk) (Point blk)) e m bSBF
[cTxSubmission2Codec] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec (TxSubmission2 (GenTxId blk) (GenTx blk)) e m bTX
[cKeepAliveCodec] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec KeepAlive e m bKA
[cPeerSharingCodec] :: Codecs blk addr e m bCS bSCS bBF bSBF bTX bKA bPS -> Codec (PeerSharing addr) e m bPS

-- | Protocol codecs for the node-to-node protocols
defaultCodecs :: forall m blk addr. (IOLike m, SerialiseNodeToNodeConstraints blk) => CodecConfig blk -> BlockNodeToNodeVersion blk -> (NodeToNodeVersion -> addr -> Encoding) -> (NodeToNodeVersion -> forall s. Decoder s addr) -> NodeToNodeVersion -> Codecs blk addr DeserialiseFailure m ByteString ByteString ByteString ByteString ByteString ByteString ByteString

-- | Identity codecs used in tests.
identityCodecs :: Monad m => Codecs blk addr CodecFailure m (AnyMessage (ChainSync (Header blk) (Point blk) (Tip blk))) (AnyMessage (ChainSync (SerialisedHeader blk) (Point blk) (Tip blk))) (AnyMessage (BlockFetch blk (Point blk))) (AnyMessage (BlockFetch (Serialised blk) (Point blk))) (AnyMessage (TxSubmission2 (GenTxId blk) (GenTx blk))) (AnyMessage KeepAlive) (AnyMessage (PeerSharing addr))

-- | Per mini-protocol byte limits; For each mini-protocol they provide
--   per-state byte size limits, i.e. how much data can arrive from the
--   network.
--   
--   They don't depend on the instantiation of the protocol parameters
--   (which block type is used, etc.), hence the use of
--   <tt>RankNTypes</tt>.
data ByteLimits bCS bBF bTX bKA
byteLimits :: ByteLimits ByteString ByteString ByteString ByteString
noByteLimits :: ByteLimits bCS bBF bTX bKA

-- | A record of <a>Tracer</a>s for the different protocols.
type Tracers m peer blk e = Tracers' peer blk e (Tracer m)
data Tracers' peer blk e f
Tracers :: f (TraceLabelPeer peer (TraceSendRecv (ChainSync (Header blk) (Point blk) (Tip blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (ChainSync (SerialisedHeader blk) (Point blk) (Tip blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (BlockFetch blk (Point blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (BlockFetch (Serialised blk) (Point blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (TxSubmission2 (GenTxId blk) (GenTx blk)))) -> Tracers' peer blk e f
[tChainSyncTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (ChainSync (Header blk) (Point blk) (Tip blk))))
[tChainSyncSerialisedTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (ChainSync (SerialisedHeader blk) (Point blk) (Tip blk))))
[tBlockFetchTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (BlockFetch blk (Point blk))))
[tBlockFetchSerialisedTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (BlockFetch (Serialised blk) (Point blk))))
[tTxSubmission2Tracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (TxSubmission2 (GenTxId blk) (GenTx blk))))

-- | Use a <a>nullTracer</a> for each protocol.
nullTracers :: Monad m => Tracers m peer blk e
showTracers :: (Show blk, Show peer, Show (Header blk), Show (GenTx blk), Show (GenTxId blk), HasHeader blk, HasNestedContent Header blk) => Tracer m String -> Tracers m peer blk e

-- | Applications for the node-to-node protocols
--   
--   See <a>MuxApplication</a>
data Apps m addr bCS bBF bTX bKA bPS a b
Apps :: ClientApp m addr bCS a -> ServerApp m addr bCS b -> ClientApp m addr bBF a -> ServerApp m addr bBF b -> ClientApp m addr bTX a -> ServerApp m addr bTX b -> ClientApp m addr bKA a -> ServerApp m addr bKA b -> ClientApp m addr bPS a -> ServerApp m addr bPS b -> Apps m addr bCS bBF bTX bKA bPS a b

-- | Start a chain sync client that communicates with the given upstream
--   node.
[aChainSyncClient] :: Apps m addr bCS bBF bTX bKA bPS a b -> ClientApp m addr bCS a

-- | Start a chain sync server.
[aChainSyncServer] :: Apps m addr bCS bBF bTX bKA bPS a b -> ServerApp m addr bCS b

-- | Start a block fetch client that communicates with the given upstream
--   node.
[aBlockFetchClient] :: Apps m addr bCS bBF bTX bKA bPS a b -> ClientApp m addr bBF a

-- | Start a block fetch server.
[aBlockFetchServer] :: Apps m addr bCS bBF bTX bKA bPS a b -> ServerApp m addr bBF b

-- | Start a transaction submission v2 client that communicates with the
--   given upstream node.
[aTxSubmission2Client] :: Apps m addr bCS bBF bTX bKA bPS a b -> ClientApp m addr bTX a

-- | Start a transaction submission v2 server.
[aTxSubmission2Server] :: Apps m addr bCS bBF bTX bKA bPS a b -> ServerApp m addr bTX b

-- | Start a keep-alive client.
[aKeepAliveClient] :: Apps m addr bCS bBF bTX bKA bPS a b -> ClientApp m addr bKA a

-- | Start a keep-alive server.
[aKeepAliveServer] :: Apps m addr bCS bBF bTX bKA bPS a b -> ServerApp m addr bKA b

-- | Start a peer-sharing client.
[aPeerSharingClient] :: Apps m addr bCS bBF bTX bKA bPS a b -> ClientApp m addr bPS a

-- | Start a peer-sharing server.
[aPeerSharingServer] :: Apps m addr bCS bBF bTX bKA bPS a b -> ServerApp m addr bPS b

-- | A node-to-node application
type ClientApp m addr bytes a = NodeToNodeVersion -> ExpandedInitiatorContext addr m -> Channel m bytes -> m (a, Maybe bytes)
type ServerApp m addr bytes a = NodeToNodeVersion -> ResponderContext addr -> Channel m bytes -> m (a, Maybe bytes)

-- | Construct the <tt>NetworkApplication</tt> for the node-to-node
--   protocols
mkApps :: forall m addrNTN addrNTC blk e bCS bBF bTX bKA bPS. (IOLike m, MonadTimer m, Ord addrNTN, Exception e, LedgerSupportsProtocol blk, ShowProxy blk, ShowProxy (Header blk), ShowProxy (TxId (GenTx blk)), ShowProxy (GenTx blk)) => NodeKernel m addrNTN addrNTC blk -> Tracers m (ConnectionId addrNTN) blk e -> (NodeToNodeVersion -> Codecs blk addrNTN e m bCS bCS bBF bBF bTX bKA bPS) -> ByteLimits bCS bBF bTX bKA -> m ChainSyncTimeout -> ReportPeerMetrics m (ConnectionId addrNTN) -> Handlers m addrNTN blk -> Apps m addrNTN bCS bBF bTX bKA bPS NodeToNodeInitiatorResult ()

-- | A projection from <tt>NetworkApplication</tt> to a client-side
--   <a>OuroborosApplication</a> for the node-to-node protocols.
--   
--   Implementation note: network currently doesn't enable protocols
--   conditional on the protocol version, but it eventually may; this is
--   why <tt>_version</tt> is currently unused.
initiator :: MiniProtocolParameters -> NodeToNodeVersion -> PeerSharing -> Apps m addr b b b b b a c -> OuroborosBundleWithExpandedCtx 'InitiatorMode addr b m a Void

-- | A bi-directional network application.
--   
--   Implementation note: network currently doesn't enable protocols
--   conditional on the protocol version, but it eventually may; this is
--   why <tt>_version</tt> is currently unused.
initiatorAndResponder :: MiniProtocolParameters -> NodeToNodeVersion -> PeerSharing -> Apps m addr b b b b b a c -> OuroborosBundleWithExpandedCtx 'InitiatorResponderMode addr b m a c
data () => ChainSyncTimeout
ChainSyncTimeout :: Maybe DiffTime -> Maybe DiffTime -> Maybe DiffTime -> Maybe DiffTime -> ChainSyncTimeout
[canAwaitTimeout] :: ChainSyncTimeout -> Maybe DiffTime
[intersectTimeout] :: ChainSyncTimeout -> Maybe DiffTime
[mustReplyTimeout] :: ChainSyncTimeout -> Maybe DiffTime
[idleTimeout] :: ChainSyncTimeout -> Maybe DiffTime
instance (forall a. GHC.Base.Semigroup (f a)) => GHC.Base.Semigroup (Ouroboros.Consensus.Network.NodeToNode.Tracers' peer blk e f)


-- | Intended for qualified import
module Ouroboros.Consensus.Network.NodeToClient

-- | Protocol handlers for node-to-client (local) communication
data Handlers m peer blk
Handlers :: (Follower m blk (WithPoint blk (Serialised blk)) -> ChainSyncServer (Serialised blk) (Point blk) (Tip blk) m ()) -> LocalTxSubmissionServer (GenTx blk) (ApplyTxErr blk) m () -> LocalStateQueryServer blk (Point blk) (Query blk) m () -> LocalTxMonitorServer (GenTxId blk) (GenTx blk) SlotNo m () -> Handlers m peer blk
[hChainSyncServer] :: Handlers m peer blk -> Follower m blk (WithPoint blk (Serialised blk)) -> ChainSyncServer (Serialised blk) (Point blk) (Tip blk) m ()
[hTxSubmissionServer] :: Handlers m peer blk -> LocalTxSubmissionServer (GenTx blk) (ApplyTxErr blk) m ()
[hStateQueryServer] :: Handlers m peer blk -> LocalStateQueryServer blk (Point blk) (Query blk) m ()
[hTxMonitorServer] :: Handlers m peer blk -> LocalTxMonitorServer (GenTxId blk) (GenTx blk) SlotNo m ()
mkHandlers :: forall m blk addrNTN addrNTC. (IOLike m, LedgerSupportsMempool blk, LedgerSupportsProtocol blk, QueryLedger blk, ConfigSupportsNode blk) => NodeKernelArgs m addrNTN addrNTC blk -> NodeKernel m addrNTN addrNTC blk -> Handlers m addrNTC blk
type ClientCodecs blk m = Codecs' blk blk DeserialiseFailure m ByteString ByteString ByteString ByteString
type Codecs blk e m bCS bTX bSQ bTM = Codecs' blk (Serialised blk) e m bCS bTX bSQ bTM

-- | Node-to-client protocol codecs needed to run <a>Handlers</a>.
data Codecs' blk serialisedBlk e m bCS bTX bSQ bTM
Codecs :: Codec (ChainSync serialisedBlk (Point blk) (Tip blk)) e m bCS -> Codec (LocalTxSubmission (GenTx blk) (ApplyTxErr blk)) e m bTX -> Codec (LocalStateQuery blk (Point blk) (Query blk)) e m bSQ -> Codec (LocalTxMonitor (GenTxId blk) (GenTx blk) SlotNo) e m bTM -> Codecs' blk serialisedBlk e m bCS bTX bSQ bTM
[cChainSyncCodec] :: Codecs' blk serialisedBlk e m bCS bTX bSQ bTM -> Codec (ChainSync serialisedBlk (Point blk) (Tip blk)) e m bCS
[cTxSubmissionCodec] :: Codecs' blk serialisedBlk e m bCS bTX bSQ bTM -> Codec (LocalTxSubmission (GenTx blk) (ApplyTxErr blk)) e m bTX
[cStateQueryCodec] :: Codecs' blk serialisedBlk e m bCS bTX bSQ bTM -> Codec (LocalStateQuery blk (Point blk) (Query blk)) e m bSQ
[cTxMonitorCodec] :: Codecs' blk serialisedBlk e m bCS bTX bSQ bTM -> Codec (LocalTxMonitor (GenTxId blk) (GenTx blk) SlotNo) e m bTM
type DefaultCodecs blk m = Codecs' blk (Serialised blk) DeserialiseFailure m ByteString ByteString ByteString ByteString

-- | Protocol codecs for the node-to-client protocols which serialise <i>
--   deserialise blocks in </i>chain-sync/ protocol.
clientCodecs :: forall m blk. (MonadST m, SerialiseNodeToClientConstraints blk, ShowQuery (BlockQuery blk), StandardHash blk, Serialise (HeaderHash blk)) => CodecConfig blk -> BlockNodeToClientVersion blk -> NodeToClientVersion -> ClientCodecs blk m

-- | Protocol codecs for the node-to-client protocols
--   
--   We pass the <a>BlockConfig</a> here, even though it is currently
--   unused. If at any point we want to introduce local protocols that for
--   example send Byron blocks or headers across, we will need to have the
--   epoch size, which comes from the Byron config. Unlike the full
--   <tt>TopLevelConfig</tt>, it should not be difficult for a wallet to
--   construct the <a>BlockConfig</a>.
--   
--   NOTE: Somewhat confusingly, <tt>pcChainSyncCodec</tt> currently
--   <i>does</i> send Byron blocks across, but it does not deserialize them
--   (the user of the codec is itself responsible for doing that), which is
--   why it currently does not need the config.
--   
--   Implementation mode: currently none of the consensus encoders/decoders
--   do anything different based on the version, so <tt>_version</tt> is
--   unused; it's just that not all codecs are used, depending on the
--   version number.
defaultCodecs :: forall m blk. (MonadST m, SerialiseNodeToClientConstraints blk, ShowQuery (BlockQuery blk), StandardHash blk, Serialise (HeaderHash blk)) => CodecConfig blk -> BlockNodeToClientVersion blk -> NodeToClientVersion -> DefaultCodecs blk m

-- | Identity codecs used in tests.
identityCodecs :: (Monad m, QueryLedger blk) => Codecs blk CodecFailure m (AnyMessage (ChainSync (Serialised blk) (Point blk) (Tip blk))) (AnyMessage (LocalTxSubmission (GenTx blk) (ApplyTxErr blk))) (AnyMessage (LocalStateQuery blk (Point blk) (Query blk))) (AnyMessage (LocalTxMonitor (GenTxId blk) (GenTx blk) SlotNo))

-- | A record of <a>Tracer</a>s for the different protocols.
type Tracers m peer blk e = Tracers' peer blk e (Tracer m)
data Tracers' peer blk e f
Tracers :: f (TraceLabelPeer peer (TraceSendRecv (ChainSync (Serialised blk) (Point blk) (Tip blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (LocalTxSubmission (GenTx blk) (ApplyTxErr blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (LocalStateQuery blk (Point blk) (Query blk)))) -> f (TraceLabelPeer peer (TraceSendRecv (LocalTxMonitor (GenTxId blk) (GenTx blk) SlotNo))) -> Tracers' peer blk e f
[tChainSyncTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (ChainSync (Serialised blk) (Point blk) (Tip blk))))
[tTxSubmissionTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (LocalTxSubmission (GenTx blk) (ApplyTxErr blk))))
[tStateQueryTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (LocalStateQuery blk (Point blk) (Query blk))))
[tTxMonitorTracer] :: Tracers' peer blk e f -> f (TraceLabelPeer peer (TraceSendRecv (LocalTxMonitor (GenTxId blk) (GenTx blk) SlotNo)))

-- | Use a <a>nullTracer</a> for each protocol.
nullTracers :: Monad m => Tracers m peer blk e
showTracers :: (Show peer, Show (GenTx blk), Show (GenTxId blk), Show (ApplyTxErr blk), ShowQuery (BlockQuery blk), HasHeader blk) => Tracer m String -> Tracers m peer blk e

-- | A node-to-client application
type App m peer bytes a = peer -> Channel m bytes -> m (a, Maybe bytes)

-- | Applications for the node-to-client (i.e., local) protocols
--   
--   See <a>MuxApplication</a>
data Apps m peer bCS bTX bSQ bTM a
Apps :: App m peer bCS a -> App m peer bTX a -> App m peer bSQ a -> App m peer bTM a -> Apps m peer bCS bTX bSQ bTM a

-- | Start a local chain sync server.
[aChainSyncServer] :: Apps m peer bCS bTX bSQ bTM a -> App m peer bCS a

-- | Start a local transaction submission server.
[aTxSubmissionServer] :: Apps m peer bCS bTX bSQ bTM a -> App m peer bTX a

-- | Start a local state query server.
[aStateQueryServer] :: Apps m peer bCS bTX bSQ bTM a -> App m peer bSQ a

-- | Start a local transaction monitor server
[aTxMonitorServer] :: Apps m peer bCS bTX bSQ bTM a -> App m peer bTM a

-- | Construct the <tt>NetworkApplication</tt> for the node-to-client
--   protocols
mkApps :: forall m addrNTN addrNTC blk e bCS bTX bSQ bTM. (IOLike m, Exception e, ShowProxy blk, ShowProxy (ApplyTxErr blk), ShowProxy (BlockQuery blk), ShowProxy (GenTx blk), ShowProxy (GenTxId blk), ShowQuery (BlockQuery blk)) => NodeKernel m addrNTN addrNTC blk -> Tracers m addrNTC blk e -> Codecs blk e m bCS bTX bSQ bTM -> Handlers m addrNTC blk -> Apps m addrNTC bCS bTX bSQ bTM ()

-- | A projection from <tt>NetworkApplication</tt> to a server-side
--   <a>OuroborosApplication</a> for the node-to-client protocols.
responder :: NodeToClientVersion -> Apps m (ConnectionId peer) b b b b a -> OuroborosApplicationWithMinimalCtx 'ResponderMode peer b m Void a
instance (forall a. GHC.Base.Semigroup (f a)) => GHC.Base.Semigroup (Ouroboros.Consensus.Network.NodeToClient.Tracers' peer blk e f)


-- | Run the whole Node
--   
--   Intended for qualified import.
module Ouroboros.Consensus.Node

-- | Combination of <a>runWith</a> and <tt>stdLowLevelRunArgsIO</tt>
run :: forall blk p2p. RunNode blk => RunNodeArgs IO RemoteAddress LocalAddress blk p2p -> StdRunNodeArgs IO blk p2p -> IO ()

-- | Start a node.
--   
--   This opens the <a>ChainDB</a>, sets up the <a>NodeKernel</a> and
--   initialises the network layer.
--   
--   This function runs forever unless an exception is thrown.
runWith :: forall m addrNTN addrNTC versionDataNTN versionDataNTC blk p2p. (RunNode blk, IOLike m, Hashable addrNTN, NetworkIO m, NetworkAddr addrNTN) => RunNodeArgs m addrNTN addrNTC blk p2p -> (NodeToNodeVersion -> addrNTN -> Encoding) -> (NodeToNodeVersion -> forall s. Decoder s addrNTN) -> LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk p2p -> m ()

-- | Higher-level arguments that can determine the
--   <a>LowLevelRunNodeArgs</a> under some usual assumptions for realistic
--   use cases such as in <tt>cardano-node</tt>.
--   
--   See <a>stdLowLevelRunNodeArgsIO</a>.
data StdRunNodeArgs m blk (p2p :: P2P)
StdRunNodeArgs :: Maybe Word -> Maybe Word -> Bool -> SnapshotInterval -> FilePath -> Arguments Socket RemoteAddress LocalSocket LocalAddress -> ExtraArguments p2p m -> Tracers RemoteAddress NodeToNodeVersion LocalAddress NodeToClientVersion IO -> ExtraTracers p2p -> Bool -> Tracer m (TraceEvent blk) -> Maybe MempoolCapacityBytesOverride -> Maybe (m ChainSyncTimeout) -> StdRunNodeArgs m blk (p2p :: P2P)
[srnBfcMaxConcurrencyBulkSync] :: StdRunNodeArgs m blk (p2p :: P2P) -> Maybe Word
[srnBfcMaxConcurrencyDeadline] :: StdRunNodeArgs m blk (p2p :: P2P) -> Maybe Word

-- | If <tt>True</tt>, validate the ChainDB on init no matter what
[srnChainDbValidateOverride] :: StdRunNodeArgs m blk (p2p :: P2P) -> Bool
[srnSnapshotInterval] :: StdRunNodeArgs m blk (p2p :: P2P) -> SnapshotInterval

-- | Location of the DBs
[srnDatabasePath] :: StdRunNodeArgs m blk (p2p :: P2P) -> FilePath
[srnDiffusionArguments] :: StdRunNodeArgs m blk (p2p :: P2P) -> Arguments Socket RemoteAddress LocalSocket LocalAddress
[srnDiffusionArgumentsExtra] :: StdRunNodeArgs m blk (p2p :: P2P) -> ExtraArguments p2p m
[srnDiffusionTracers] :: StdRunNodeArgs m blk (p2p :: P2P) -> Tracers RemoteAddress NodeToNodeVersion LocalAddress NodeToClientVersion IO
[srnDiffusionTracersExtra] :: StdRunNodeArgs m blk (p2p :: P2P) -> ExtraTracers p2p

-- | If <tt>False</tt>, then the node will limit the negotiated NTN and NTC
--   versions to the latest " official " release (as chosen by Network and
--   Consensus Team, with input from Node Team)
[srnEnableInDevelopmentVersions] :: StdRunNodeArgs m blk (p2p :: P2P) -> Bool
[srnTraceChainDB] :: StdRunNodeArgs m blk (p2p :: P2P) -> Tracer m (TraceEvent blk)

-- | Determine whether to use the system default mempool capacity or
--   explicitly set capacity of the mempool.
[srnMaybeMempoolCapacityOverride] :: StdRunNodeArgs m blk (p2p :: P2P) -> Maybe MempoolCapacityBytesOverride

-- | A custom timeout for ChainSync.
[srnChainSyncTimeout] :: StdRunNodeArgs m blk (p2p :: P2P) -> Maybe (m ChainSyncTimeout)
stdBfcSaltIO :: IO Int
stdChainSyncTimeout :: IO ChainSyncTimeout
stdKeepAliveRngIO :: IO StdGen

-- | Conveniently packaged <a>LowLevelRunNodeArgs</a> arguments from a
--   standard non-testing invocation.
stdLowLevelRunNodeArgsIO :: forall blk p2p. RunNode blk => RunNodeArgs IO RemoteAddress LocalAddress blk p2p -> StdRunNodeArgs IO blk p2p -> IO (LowLevelRunNodeArgs IO RemoteAddress LocalAddress NodeToNodeVersionData NodeToClientVersionData blk p2p)

-- | How to locate the ChainDB on disk
stdMkChainDbHasFS :: FilePath -> RelativeMountPoint -> SomeHasFS IO
stdRunDataDiffusion :: Tracers RemoteAddress NodeToNodeVersion LocalAddress NodeToClientVersion IO -> ExtraTracers p2p -> Arguments Socket RemoteAddress LocalSocket LocalAddress -> ExtraArguments p2p IO -> Applications RemoteAddress NodeToNodeVersion NodeToNodeVersionData LocalAddress NodeToClientVersion NodeToClientVersionData IO NodeToNodeInitiatorResult -> ExtraApplications p2p RemoteAddress IO NodeToNodeInitiatorResult -> IO ()
stdVersionDataNTC :: NetworkMagic -> NodeToClientVersionData
stdVersionDataNTN :: NetworkMagic -> DiffusionMode -> PeerSharing -> NodeToNodeVersionData

-- | Check the DB marker, lock the DB and look for the clean shutdown
--   marker.
--   
--   Run the body action with the DB locked.
stdWithCheckedDB :: forall blk a. (StandardHash blk, Typeable blk) => Proxy blk -> FilePath -> NetworkMagic -> (LastShutDownWasClean -> (ChainDB IO blk -> IO a -> IO a) -> IO a) -> IO a

-- | P2P Switch
data NetworkP2PMode (p2p :: P2P)
[EnabledP2PMode] :: NetworkP2PMode 'P2P
[DisabledP2PMode] :: NetworkP2PMode 'NonP2P
newtype () => RelativeMountPoint
RelativeMountPoint :: FilePath -> RelativeMountPoint
data () => TraceEvent blk
TraceAddBlockEvent :: TraceAddBlockEvent blk -> TraceEvent blk
TraceFollowerEvent :: TraceFollowerEvent blk -> TraceEvent blk
TraceCopyToImmutableDBEvent :: TraceCopyToImmutableDBEvent blk -> TraceEvent blk
TraceGCEvent :: TraceGCEvent blk -> TraceEvent blk
TraceInitChainSelEvent :: TraceInitChainSelEvent blk -> TraceEvent blk
TraceOpenEvent :: TraceOpenEvent blk -> TraceEvent blk
TraceIteratorEvent :: TraceIteratorEvent blk -> TraceEvent blk
TraceSnapshotEvent :: TraceSnapshotEvent blk -> TraceEvent blk
TraceLedgerReplayEvent :: TraceReplayEvent blk -> TraceEvent blk
TraceImmutableDBEvent :: TraceEvent blk -> TraceEvent blk
TraceVolatileDBEvent :: TraceEvent blk -> TraceEvent blk
data () => ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk
ChainDbArgs :: SomeHasFS m -> SomeHasFS m -> SomeHasFS m -> ValidationPolicy -> BlockValidationPolicy -> BlocksPerFile -> DiskPolicy -> HKD f (TopLevelConfig blk) -> HKD f ChunkInfo -> HKD f (blk -> Bool) -> HKD f (m (ExtLedgerState blk)) -> HKD f (CheckInFuture m blk) -> CacheConfig -> Tracer m (TraceEvent blk) -> Tracer m (LedgerDB' blk) -> HKD f (ResourceRegistry m) -> DiffTime -> DiffTime -> Word -> ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk
[cdbHasFSImmutableDB] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> SomeHasFS m
[cdbHasFSVolatileDB] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> SomeHasFS m
[cdbHasFSLgrDB] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> SomeHasFS m
[cdbImmutableDbValidation] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> ValidationPolicy
[cdbVolatileDbValidation] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> BlockValidationPolicy
[cdbMaxBlocksPerFile] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> BlocksPerFile
[cdbDiskPolicy] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> DiskPolicy
[cdbTopLevelConfig] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> HKD f (TopLevelConfig blk)
[cdbChunkInfo] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> HKD f ChunkInfo
[cdbCheckIntegrity] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> HKD f (blk -> Bool)
[cdbGenesis] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> HKD f (m (ExtLedgerState blk))
[cdbCheckInFuture] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> HKD f (CheckInFuture m blk)
[cdbImmutableDbCacheConfig] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> CacheConfig
[cdbTracer] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> Tracer m (TraceEvent blk)
[cdbTraceLedger] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> Tracer m (LedgerDB' blk)
[cdbRegistry] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> HKD f (ResourceRegistry m)
[cdbGcDelay] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> DiffTime
[cdbGcInterval] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> DiffTime
[cdbBlocksToAddSize] :: ChainDbArgs (f :: Type -> Type) (m :: Type -> Type) blk -> Word
data () => HardForkBlockchainTimeArgs (m :: Type -> Type) blk
HardForkBlockchainTimeArgs :: m BackoffDelay -> STM m (LedgerState blk) -> LedgerConfig blk -> ResourceRegistry m -> SystemTime m -> Tracer m (TraceBlockchainTimeEvent RelativeTime) -> NominalDiffTime -> HardForkBlockchainTimeArgs (m :: Type -> Type) blk
[hfbtBackoffDelay] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> m BackoffDelay
[hfbtGetLedgerState] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> STM m (LedgerState blk)
[hfbtLedgerConfig] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> LedgerConfig blk
[hfbtRegistry] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> ResourceRegistry m
[hfbtSystemTime] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> SystemTime m
[hfbtTracer] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> Tracer m (TraceBlockchainTimeEvent RelativeTime)
[hfbtMaxClockRewind] :: HardForkBlockchainTimeArgs (m :: Type -> Type) blk -> NominalDiffTime

-- | Did the ChainDB already have existing clean-shutdown marker on disk?
newtype LastShutDownWasClean
LastShutDownWasClean :: Bool -> LastShutDownWasClean

-- | Arguments that usually only tests <i>directly</i> specify.
--   
--   A non-testing invocation probably wouldn't explicitly provide these
--   values to <a>runWith</a>. The <tt>cardano-node</tt>, for example,
--   instead calls the <a>run</a> abbreviation, which uses
--   <a>stdLowLevelRunNodeArgsIO</a> to indirectly specify these low-level
--   values from the higher-level <a>StdRunNodeArgs</a>.
data LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P)
LowLevelRunNodeArgs :: (forall a. (LastShutDownWasClean -> (ChainDB m blk -> m a -> m a) -> m a) -> m a) -> ChainDbArgs Defaults m blk -> (ChainDbArgs Identity m blk -> ChainDbArgs Identity m blk) -> (NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk -> NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk) -> Int -> StdGen -> (HardForkBlockchainTimeArgs m blk -> HardForkBlockchainTimeArgs m blk) -> m ChainSyncTimeout -> (ResourceRegistry m -> Applications addrNTN NodeToNodeVersion versionDataNTN addrNTC NodeToClientVersion versionDataNTC m NodeToNodeInitiatorResult -> ExtraApplications p2p addrNTN m NodeToNodeInitiatorResult -> m ()) -> versionDataNTC -> versionDataNTN -> Map NodeToNodeVersion (BlockNodeToNodeVersion blk) -> Map NodeToClientVersion (BlockNodeToClientVersion blk) -> ClockSkew -> LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P)

-- | An action that will receive a marker indicating whether the previous
--   shutdown was considered clean and a wrapper for installing a handler
--   to create a clean file on exit if needed. See <a>runWithCheckedDB</a>.
[llrnWithCheckedDB] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> forall a. (LastShutDownWasClean -> (ChainDB m blk -> m a -> m a) -> m a) -> m a

-- | The " static " ChainDB arguments
[llrnChainDbArgsDefaults] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> ChainDbArgs Defaults m blk

-- | Customise the <a>ChainDbArgs</a>
[llrnCustomiseChainDbArgs] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> ChainDbArgs Identity m blk -> ChainDbArgs Identity m blk

-- | Customise the <tt>NodeArgs</tt>
[llrnCustomiseNodeKernelArgs] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk -> NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk

-- | Ie <a>bfcSalt</a>
[llrnBfcSalt] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> Int

-- | Ie <a>$sel:keepAliveRng:NodeKernelArgs</a>
[llrnKeepAliveRng] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> StdGen

-- | Customise the <a>HardForkBlockchainTimeArgs</a>
[llrnCustomiseHardForkBlockchainTimeArgs] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> HardForkBlockchainTimeArgs m blk -> HardForkBlockchainTimeArgs m blk

-- | See <a>ChainSyncTimeout</a>
[llrnChainSyncTimeout] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> m ChainSyncTimeout

-- | How to run the data diffusion applications
--   
--   <a>run</a> will not return before this does.
[llrnRunDataDiffusion] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> ResourceRegistry m -> Applications addrNTN NodeToNodeVersion versionDataNTN addrNTC NodeToClientVersion versionDataNTC m NodeToNodeInitiatorResult -> ExtraApplications p2p addrNTN m NodeToNodeInitiatorResult -> m ()
[llrnVersionDataNTC] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> versionDataNTC
[llrnVersionDataNTN] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> versionDataNTN

-- | node-to-node protocol versions to run.
[llrnNodeToNodeVersions] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> Map NodeToNodeVersion (BlockNodeToNodeVersion blk)

-- | node-to-client protocol versions to run.
[llrnNodeToClientVersions] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> Map NodeToClientVersion (BlockNodeToClientVersion blk)

-- | Maximum clock skew
[llrnMaxClockSkew] :: LowLevelRunNodeArgs m addrNTN addrNTC versionDataNTN versionDataNTC blk (p2p :: P2P) -> ClockSkew
data () => MempoolCapacityBytesOverride
NoMempoolCapacityBytesOverride :: MempoolCapacityBytesOverride
MempoolCapacityBytesOverride :: !MempoolCapacityBytes -> MempoolCapacityBytesOverride

-- | Interface against running relay node
data NodeKernel m addrNTN addrNTC blk
NodeKernel :: ChainDB m blk -> Mempool m blk -> TopLevelConfig blk -> FetchClientRegistry (ConnectionId addrNTN) (Header blk) blk m -> STM m FetchMode -> StrictTVar m (Map (ConnectionId addrNTN) (StrictTVar m (AnchoredFragment (Header blk)))) -> PeerSharingRegistry addrNTN m -> Tracers m (ConnectionId addrNTN) addrNTC blk -> ([BlockForging m blk] -> m ()) -> NodeKernel m addrNTN addrNTC blk

-- | The <a>ChainDB</a> of the node
[$sel:getChainDB:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> ChainDB m blk

-- | The node's mempool
[$sel:getMempool:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> Mempool m blk

-- | The node's top-level static configuration
[$sel:getTopLevelConfig:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> TopLevelConfig blk

-- | The fetch client registry, used for the block fetch clients.
[$sel:getFetchClientRegistry:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> FetchClientRegistry (ConnectionId addrNTN) (Header blk) blk m

-- | The fetch mode, used by diffusion.
[$sel:getFetchMode:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> STM m FetchMode

-- | Read the current candidates
[$sel:getNodeCandidates:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> StrictTVar m (Map (ConnectionId addrNTN) (StrictTVar m (AnchoredFragment (Header blk))))

-- | Read the current peer sharing registry, used for interacting with the
--   PeerSharing protocol
[$sel:getPeerSharingRegistry:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> PeerSharingRegistry addrNTN m

-- | The node's tracers
[$sel:getTracers:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> Tracers m (ConnectionId addrNTN) addrNTC blk

-- | Set block forging
--   
--   When set with the empty list '[]' block forging will be disabled.
[$sel:setBlockForging:NodeKernel] :: NodeKernel m addrNTN addrNTC blk -> [BlockForging m blk] -> m ()

-- | Arguments required when initializing a node
data NodeKernelArgs m addrNTN addrNTC blk
NodeKernelArgs :: Tracers m (ConnectionId addrNTN) addrNTC blk -> ResourceRegistry m -> TopLevelConfig blk -> BlockchainTime m -> ChainDB m blk -> (StorageConfig blk -> InitChainDB m blk -> m ()) -> SomeHeaderInFutureCheck m blk -> (Header blk -> SizeInBytes) -> MempoolCapacityBytesOverride -> MiniProtocolParameters -> BlockFetchConfiguration -> StdGen -> NodeKernelArgs m addrNTN addrNTC blk
[$sel:tracers:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> Tracers m (ConnectionId addrNTN) addrNTC blk
[$sel:registry:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> ResourceRegistry m
[$sel:cfg:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> TopLevelConfig blk
[$sel:btime:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> BlockchainTime m
[$sel:chainDB:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> ChainDB m blk
[$sel:initChainDB:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> StorageConfig blk -> InitChainDB m blk -> m ()
[$sel:chainSyncFutureCheck:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> SomeHeaderInFutureCheck m blk
[$sel:blockFetchSize:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> Header blk -> SizeInBytes
[$sel:mempoolCapacityOverride:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> MempoolCapacityBytesOverride
[$sel:miniProtocolParameters:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> MiniProtocolParameters
[$sel:blockFetchConfiguration:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> BlockFetchConfiguration
[$sel:keepAliveRng:NodeKernelArgs] :: NodeKernelArgs m addrNTN addrNTC blk -> StdGen
data () => ProtocolInfo b
ProtocolInfo :: TopLevelConfig b -> ExtLedgerState b -> ProtocolInfo b
[pInfoConfig] :: ProtocolInfo b -> TopLevelConfig b
[pInfoInitLedger] :: ProtocolInfo b -> ExtLedgerState b
class (LedgerSupportsProtocol blk, InspectLedger blk, HasHardForkHistory blk, LedgerSupportsMempool blk, HasTxId GenTx blk, QueryLedger blk, SupportedNetworkProtocolVersion blk, ConfigSupportsNode blk, ConvertRawHash blk, CommonProtocolParams blk, HasBinaryBlockInfo blk, SerialiseDiskConstraints blk, SerialiseNodeToNodeConstraints blk, SerialiseNodeToClientConstraints blk, LedgerSupportsPeerSelection blk, NodeInitStorage blk, BlockSupportsMetrics blk, Show CannotForge blk, Show ForgeStateInfo blk, Show ForgeStateUpdateError blk, ShowProxy blk, ShowProxy ApplyTxErr blk, ShowProxy GenTx blk, ShowProxy Header blk, ShowProxy BlockQuery blk, ShowProxy TxId GenTx blk) => RunNode blk

-- | Arguments expected from any invocation of <a>runWith</a>, whether by
--   deployed code, tests, etc.
data RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P)
RunNodeArgs :: Tracers m (ConnectionId addrNTN) (ConnectionId addrNTC) blk -> Tracers m (ConnectionId addrNTN) blk DeserialiseFailure -> Tracers m (ConnectionId addrNTC) blk DeserialiseFailure -> ProtocolInfo blk -> (ResourceRegistry m -> NodeKernel m addrNTN (ConnectionId addrNTC) blk -> m ()) -> NetworkP2PMode p2p -> PeerSharing -> RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P)

-- | Consensus tracers
[rnTraceConsensus] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> Tracers m (ConnectionId addrNTN) (ConnectionId addrNTC) blk

-- | Protocol tracers for node-to-node communication
[rnTraceNTN] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> Tracers m (ConnectionId addrNTN) blk DeserialiseFailure

-- | Protocol tracers for node-to-client communication
[rnTraceNTC] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> Tracers m (ConnectionId addrNTC) blk DeserialiseFailure

-- | Protocol info
[rnProtocolInfo] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> ProtocolInfo blk

-- | Hook called after the initialisation of the <a>NodeKernel</a>
--   
--   Called on the <a>NodeKernel</a> after creating it, but before the
--   network layer is initialised.
[rnNodeKernelHook] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> ResourceRegistry m -> NodeKernel m addrNTN (ConnectionId addrNTC) blk -> m ()

-- | Network P2P Mode switch
[rnEnableP2P] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> NetworkP2PMode p2p

-- | Network PeerSharing miniprotocol willingness flag
[rnPeerSharing] :: RunNodeArgs m addrNTN addrNTC blk (p2p :: P2P) -> PeerSharing

-- | A record of <a>Tracer</a>s for the node.
type Tracers m remotePeer localPeer blk = Tracers' remotePeer localPeer blk (Tracer m)
data Tracers' remotePeer localPeer blk f
Tracers :: f (TraceLabelPeer remotePeer (TraceChainSyncClientEvent blk)) -> f (TraceLabelPeer remotePeer (TraceChainSyncServerEvent blk)) -> f (TraceChainSyncServerEvent blk) -> f [TraceLabelPeer remotePeer (FetchDecision [Point (Header blk)])] -> f (TraceLabelPeer remotePeer (TraceFetchClientState (Header blk))) -> f (TraceLabelPeer remotePeer (TraceBlockFetchServerEvent blk)) -> f (TraceLabelPeer remotePeer (TraceTxSubmissionInbound (GenTxId blk) (GenTx blk))) -> f (TraceLabelPeer remotePeer (TraceTxSubmissionOutbound (GenTxId blk) (GenTx blk))) -> f (TraceLocalTxSubmissionServerEvent blk) -> f (TraceEventMempool blk) -> f (TraceLabelCreds (TraceForgeEvent blk)) -> f (TraceBlockchainTimeEvent UTCTime) -> f (TraceLabelCreds (ForgeStateInfo blk)) -> f (TraceKeepAliveClient remotePeer) -> f SomeException -> Tracers' remotePeer localPeer blk f
[chainSyncClientTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceChainSyncClientEvent blk))
[chainSyncServerHeaderTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceChainSyncServerEvent blk))
[chainSyncServerBlockTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceChainSyncServerEvent blk)
[blockFetchDecisionTracer] :: Tracers' remotePeer localPeer blk f -> f [TraceLabelPeer remotePeer (FetchDecision [Point (Header blk)])]
[blockFetchClientTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceFetchClientState (Header blk)))
[blockFetchServerTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceBlockFetchServerEvent blk))
[txInboundTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceTxSubmissionInbound (GenTxId blk) (GenTx blk)))
[txOutboundTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelPeer remotePeer (TraceTxSubmissionOutbound (GenTxId blk) (GenTx blk)))
[localTxSubmissionServerTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLocalTxSubmissionServerEvent blk)
[mempoolTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceEventMempool blk)
[forgeTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelCreds (TraceForgeEvent blk))
[blockchainTimeTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceBlockchainTimeEvent UTCTime)
[forgeStateInfoTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceLabelCreds (ForgeStateInfo blk))
[keepAliveClientTracer] :: Tracers' remotePeer localPeer blk f -> f (TraceKeepAliveClient remotePeer)
[consensusErrorTracer] :: Tracers' remotePeer localPeer blk f -> f SomeException
mkChainDbArgs :: forall m blk. (RunNode blk, IOLike m) => ResourceRegistry m -> CheckInFuture m blk -> TopLevelConfig blk -> ExtLedgerState blk -> ChunkInfo -> ChainDbArgs Defaults m blk -> ChainDbArgs Identity m blk
mkNodeKernelArgs :: forall m addrNTN addrNTC blk. (RunNode blk, IOLike m) => ResourceRegistry m -> Int -> StdGen -> TopLevelConfig blk -> Tracers m (ConnectionId addrNTN) (ConnectionId addrNTC) blk -> BlockchainTime m -> SomeHeaderInFutureCheck m blk -> ChainDB m blk -> m (NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk)

-- | We allow the user running the node to customise the
--   <a>NodeKernelArgs</a> through <a>llrnCustomiseNodeKernelArgs</a>, but
--   there are some limits to some values. This function makes sure we
--   don't exceed those limits and that the values are consistent.
nodeKernelArgsEnforceInvariants :: NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk -> NodeKernelArgs m addrNTN (ConnectionId addrNTC) blk
openChainDB :: forall m blk. (RunNode blk, IOLike m) => ResourceRegistry m -> CheckInFuture m blk -> TopLevelConfig blk -> ExtLedgerState blk -> ChainDbArgs Defaults m blk -> (ChainDbArgs Identity m blk -> ChainDbArgs Identity m blk) -> m (ChainDB m blk)
instance GHC.Classes.Eq (Ouroboros.Consensus.Node.NetworkP2PMode p2p)
instance GHC.Show.Show (Ouroboros.Consensus.Node.NetworkP2PMode p2p)
